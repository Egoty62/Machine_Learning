{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 07. 선형회귀의 기초\n",
    "## 05. 선형회귀 성능 측정하기\n",
    "- 선형회귀는 결국 연속적인 값을 갖는 $\\hat{y}$를 산출하게 됨\n",
    "- 선형회귀 문제에 댜ㅐ한 다양한 지표들을 제시\n",
    "    - 각 문제에 맞는 지표들의 특징을 잘 이용하여 실험 대상 데이터에 어떤 지표들을 사용해야 할지 사전에 파악해야함\n",
    "    - 하지만 성능 측정을 위한 지표만큼이나 데이터를 사전에 나눠서 학습하는 것도 중요\n",
    "        - 이러한 개념 중의 하나인 '훈련/테스트 분할(train/test split)'에 대해 먼저 이해 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - 훈련/테스트 분할\n",
    "- 머신러닝에서는 일반적으로 학습을 하기 위한 학습 데이터셋(train dataset)과 학습의 결과로 생성된 모델의 성능을 평가하기 위한 테스트 데이터셋(test dataset)으로 나누어 학습의 성능을 평가함\n",
    "    - 만들어진 모델이 과연 새로운 데이터셋에도 충분히 일반화(generalize)하여 처리할 수 있는지 확인해야 하기 때문\n",
    "- **과다적합(over-fit)** : 생성된 모델이 학습 데이터와 정확히 일치하는 경우\n",
    "    - 모델을 지나치게 복잡하게 학습했을 경우\n",
    "    - 특정 데이터에는 정확히 일치하지만, 새로운 데이터셋에서는 성능을 발휘할 수 없음\n",
    "- **과소적합(under-fit)** : 기존 학습 데이터를 제대로 예측하지 못하는 경우\n",
    "\n",
    "- 머신러닝에서는 적합 문제를 적절히 처리하기 위해 전체 데이터셋에서 일부 데이터를 학습 데이터와 테스트 데이터로 나누는 **홀드아웃 메서드(hold-out method)** 기법을 사용\n",
    "    - 학습 데이터셋으로 생성된 모델의 성능을 측정하기 위해 테스트 데이터셋을 사용\n",
    "    - 적절한 성능 지표를 활용하여 해당 모델의 성능을 최종적으로 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4, 5],\n",
       "        [0, 1],\n",
       "        [6, 7]]),\n",
       " array([[2, 3],\n",
       "        [8, 9]]),\n",
       " [2, 0, 3],\n",
       " [1, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 데이터를 나누기 위해서는 아래 코드와 같이 sklearn 모듈이 제공하는 train_test_split 함수 사용\n",
    "    # 해당 함수를 사용하여 x, y벡터 값을 각각 넣음\n",
    "    # 매개변수 test_size에 테스트 데이터로 사용할 데이터의 비율을 지정해야 함\n",
    "    # 마지막으로 random_state는 랜덤한 값을 기준으로 임의로 지정하는 값\n",
    "        # 이 값이 만약 같다면 같은 데이터셋에 한하여 똑같은 결과를 출력\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size= 0.33, random_state= 42)\n",
    "\n",
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - 선형회귀의 성능 측정 지표\n",
    "- 선형회귀의 성능 측정 지표에는 MAE, RMSE, 결정계수가 있음\n",
    "\n",
    "#### MAE\n",
    "- Mean Absolute Error, 평균 절대 잔차\n",
    "- 대표적인 성능 측정지표 중 하나\n",
    "- 예측값과 실제값의 차이를 절댓값으로 표현하는 지표\n",
    "\n",
    "- $MAE = \\frac{1}{n} \\displaystyle\\sum_{i = 1}^{n} \\left\\vert y_i - \\hat{y_i} \\right\\vert = \\frac{1}{n} \\displaystyle\\sum_{i = 1}^{n} \\left\\vert e_i \\right\\vert$\n",
    "    - 위 수식과 같이 모든 테스트 데이터에 대해 예측값과 실제값의 차이에 대해 절댓값을 구함\n",
    "        - 이 값을 모두 더한 후 데이터의 개수만큼 나누면 결과가 출력됨\n",
    "\n",
    "- 직관적으로 예측값과 실측값의 차이가 어느 정도인지 알 수 있음\n",
    "    - 만약 MAE가 300이라면 두 값의 차이가 평균적으로 300이라고 예상할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn 모듈로 MAE를 구하는 함수는 median_absolute_error\n",
    "# 예측값 벡터와 실제값 벡터를 해당 함수에 다음 코드와 같이 넣으면 결과를 구할 수 있음\n",
    "\n",
    "from sklearn.metrics import median_absolute_error\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "median_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE\n",
    "- Root Mean Squared Error, 평균제곱근 오차\n",
    "- MAE와 유사하나 오차에 제곱을 한 다음 모든 값을 더하여 평균을 낸 후 제곱근을 구하는 방식\n",
    "- MAE에 비해 상대적으로 값의 차이가 더 커지게 되어 있음\n",
    "    - 만약 차이가 크게 나는 값에 대해 페널티를 주고 싶으면 MAE보다 RMSE값을 사용하는 것이 더 좋은 선택\n",
    "\n",
    "- $RMSE = \\sqrt{\\frac{1}{n} \\displaystyle\\sum_{i = 1}^{n} (y_i - \\hat{y_i})^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn에서 RMSE를 직접적으로 지원하지는 않음\n",
    "    # 대신 mean_squared_error만 지원\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결정계수\n",
    "- R-squared\n",
    "- 두 개의 값의 증감이 얼마나 일관성을 가지는지 나타내는 지표\n",
    "    - 예측값이 크면 클 수록 실제값도 커지고, 작으면 실제값도 작아지는 형식\n",
    "- 결정계수는 두 개의 모델 중 어떤 모델이 조금 더 상관성이 있는지를 나타낼 수 있음\n",
    "    - 하지만 값의 차이 정도가 얼마인지는 나타낼 수 없다는 한계가 있음\n",
    "- $R^2 = 1 - \\frac{\\sum_{i} (y_i - \\hat{y_i})^2}{\\sum_{i} (y_i - \\mu)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9486081370449679"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn에서 결정계수를 구하기 위해 r2_score 사용\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "r2_score(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
